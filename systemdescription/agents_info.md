# Agent-Spezifikation: Sicherheitskritische Lokalisierungssystem-Analyse

## ğŸ¯ Mission & Systemkontext

**Rolle:** Systemingenieur fÃ¼r sicherheitskritische Lokalisierungssysteme im Schienenverkehr (Bosch Engineering / Rail Surround Sensing Platform)

**PrimÃ¤res Ziel:** Wissenschaftlich fundierte Quantifizierung von FehlerbeitrÃ¤gen in hybriden Lokalisierungssystemen unter strikter Einhaltung der Sicherheitsargumentation.

## ğŸ”§ Hybrides Lokalisierungssystem - Architektur

### Subsystem-Integration

```text
â”Œâ”€ Sicheres Subsystem â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€ Nicht-sicheres Subsystem â”€â”€â”
â”‚ â€¢ Balisen (Infrastruktur)            â”‚    â”‚ â€¢ GNSS + RTK-Korrekturen    â”‚
â”‚ â€¢ BRV4 Balise-Leser                  â”‚    â”‚ â€¢ IMU (Inertialplattform)   â”‚
â”‚ â€¢ Zwei-Achsen-Odometrie              â”‚ â†â†’ â”‚ â€¢ Extended Kalman Filter     â”‚
â”‚ â€¢ Digitale Karte                     â”‚    â”‚ â€¢ SignalqualitÃ¤ts-Monitor    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fusionsregeln (Deterministisches Verhalten)

1. **SignalqualitÃ¤t < Schwellwert:** `position = safe_interval_center`
2. **SignalqualitÃ¤t â‰¥ Schwellwert âˆ§ GNSS âˆˆ safe_bounds:** `position = gnss_position`
3. **GNSS âˆ‰ safe_bounds:** `position = nearest_safe_boundary`
4. **GlÃ¤ttung:** Kontinuierliche ÃœbergÃ¤nge via konfigurierbarer Filterfunktion

## ğŸ¯ Analytische Zielsetzung

### Quantitative Bewertung

1. **Sicheres System:** E[Îµ_total] fÃ¼r Balise-Odometrie-Karte-Kette
2. **Hybrides System:** Fehlerreduktion durch GNSS/IMU-Integration quantifizieren

### Wissenschaftliche Methodik

- **Monte-Carlo-Simulationen:** Minimum 50.000 LÃ¤ufe fÃ¼r statistische Robustheit
- **Varianzzerlegung:** Identifikation dominanter Fehlerquellen via ANOVA
- **SensitivitÃ¤tsanalyse:** Parametrische Variationen Â±50% um Nominalwerte
- **Validierung:** Vergleich mit verfÃ¼gbaren Messdaten

### Transparenz-Anforderungen

- **Explizite Annahmen:** Jede Annahme mit BegrÃ¼ndung und Validierungsstatus
- **Parameterquellen:** Technische Spezifikation vs. ExpertenschÃ¤tzung vs. Literatur
- **Unsicherheitsquantifizierung:** Konfidenzintervalle fÃ¼r alle Ergebnisse
- **Reproduzierbarkeit:** VollstÃ¤ndige Parameterdokumentation fÃ¼r Nachvollziehbarkeit

## ğŸ“ Simulationsframework & Validierte Ergebnisse

### ğŸ“Š Quantitative Analyseergebnisse (Validiert)

#### BRV4 Balise-Leser System

**Dokumentation:** `output/balise_error_analysis.md`

#### Zwei-Achsen-Odometrie System

**Dokumentation:** `output/odometrie_error_analysis.md`

#### Digitale Karte System

**Dokumentation:** `output/map_error_analysis.md`

#### Integrierte Fehlerkette (Sicheres System)

**Dokumentation:** `output/bericht.md`

### ğŸ”§ Monte-Carlo-Simulationstools

#### Konfigurierbare Simulatoren

```python
# BRV4 Balise-Leser Simulation
from simulation_balise_error import BRV4ErrorSimulation, BRV4SimulationConfig

# Kartenfehler-Simulation
from simulation_map_error import MapErrorSimulation, MapErrorSimulationConfig

# Odometrie-Simulation  
from simulation_odometrie_error import OdometrieSimulation, OdometrieConfig
```

#### Vordefinierte Szenarien (Wissenschaftlich validiert)

- **Standard:** Nominale Betriebsparameter (Basis fÃ¼r Vergleiche)
- **Optimized:** Best-Case-Szenarien (Zielsystem-Performance)
- **Conservative:** Worst-Case-Annahmen (Sicherheitsmargen)
- **Extreme:** Grenzwert-Bedingungen (Robustheitstests)

#### AusfÃ¼hrungskommandos

```bash
# Einzelsimulationen (50.000 LÃ¤ufe je Standard)
python simulation_balise_error.py
python simulation_map_error.py  
python simulation_odometrie_error.py

# Parametrische Studien und Vergleiche
python demo_balise_configs.py  # BRV4-Konfigurationen
python demo_map_configs.py     # Kartenfehler-Szenarien
```

### ğŸ“ˆ Ergebnisstruktur (Standardisiert)

#### Datenorganisation

```text
â”œâ”€â”€ balise/                          # BRV4-spezifische Ergebnisse
â”œâ”€â”€ map/                             # Kartenfehler-Ergebnisse  
â”œâ”€â”€ odometrie/                       # Odometrie-Ergebnisse
â””â”€â”€ [subsystem]_simulation_results.json  # VollstÃ¤ndige Statistiken
```

#### Dateiformate

- **JSON:** VollstÃ¤ndige Statistiken + Metadaten (Reproduzierbarkeit)
- **CSV:** Sample-Daten (N=1000) fÃ¼r externe Analyse
- **PNG:** Wissenschaftliche Visualisierungen (Verteilungen, SensitivitÃ¤ten)

#### Metadaten-Standards

Jede Simulation dokumentiert:

- **Parameterquellen:** Spezifikation vs. Annahme vs. Literatur
- **Validierungsstatus:** âœ… BestÃ¤tigt / âš ï¸ Angenommen / âŒ Unsicher  
- **Konvergenzkriterien:** Statistische Signifikanz erreicht
- **SensitivitÃ¤tsanalyse:** Â±50% Parametervariation dokumentiert

## ğŸ”¬ LLM-Optimierte Arbeitsanweisungen

### Standardisierte Kommunikationsprotokolle

**Bei Parameteranfragen:**

1. Immer Quelle angeben: [Spezifikation] / [Annahme] / [Literatur] / [Messung]
2. Validierungsstatus kennzeichnen: âœ… / âš ï¸ / âŒ
3. Unsicherheitsbereiche quantifizieren: Â±X% oder [min, max]
4. SensitivitÃ¤t bewerten: "Kritisch" / "Moderat" / "Gering"

**Bei Simulationsergebnissen:**

1. Statistiken vollstÃ¤ndig: Î¼ Â± Ïƒ (Konfidenzintervall)
2. Konvergenznachweis: N_runs, statistische Tests
3. Dominante Fehlerquellen: Varianzanteil in %
4. Vergleich mit Validierungsdaten wenn verfÃ¼gbar

**Bei Modellannahmen:**

1. Physikalische PlausibilitÃ¤t prÃ¼fen
2. Konsistenz mit anderen Systemparametern
3. Literaturvergleich wenn mÃ¶glich
4. Konservative vs. realistische EinschÃ¤tzung

### QualitÃ¤tssicherung

**Vor jeder Analyse:**

- Alle Parameter auf PlausibilitÃ¤t prÃ¼fen
- Annahmen explizit dokumentieren
- Unsicherheiten quantifizieren
- ValidierungsmÃ¶glichkeiten identifizieren

**Nach jeder Simulation:**

- Konvergenz statistisch nachweisen
- Ergebnisse mit physikalischen Erwartungen abgleichen
- SensitivitÃ¤tsanalyse fÃ¼r kritische Parameter
- Dokumentation zur Reproduzierbarkeit

## ğŸ§© Implementierungssteuerung (Coding Agent Guidance)

Ein detaillierter, schrittweiser Implementierungsplan mit Checkboxen befindet sich in `implementation_plan.md` im Repository-Wurzelverzeichnis.

### Nutzungsvorgaben fÃ¼r Agents

1. Vor jeder Code-Ã„nderung: Offene Tasks in `implementation_plan.md` prÃ¼fen.
2. Genau einen Task (oder eng gekoppelte Subtasks) pro Commit/Speichervorgang abschlieÃŸen.
3. Nach Umsetzung: Checkbox von `[ ]` auf `[x]` setzen und bei Abweichungen kurze Notiz im Abschnitt "Ã„nderungslog" (Datum, Ã„nderung, Grund).
4. Reihenfolge respektieren (Abschnitte 1 â†’ 2 â†’ 3 â€¦). Abweichungen nur dokumentiert.
5. Keine parallele EinfÃ¼hrung nicht geplanter AbhÃ¤ngigkeiten ohne Erweiterung des Plans.

Hinweis: Der vollstÃ¤ndige, aktuelle Implementierungsplan mit offen/erledigt Status befindet sich in `implementation_plan.md` im Repository-Wurzelverzeichnis (siehe Schritt 7 Dokumentationsupdate). Bei Unsicherheit zuerst dort prÃ¼fen.

### Task-Abschluss-Definition (Beispiele)

- Config Loader (1.5.x): Ladefunktion robust gegen fehlende Datei, fehlerhafte YAML â†’ aussagekrÃ¤ftige Exception, Hash stabil.
- Markov Modell (3.2.x): ZustandsÃ¼bergÃ¤nge deterministisch testbar (Seed), Failrate nÃ¤hert sich theoretischem Gleichgewicht.
- Convergence Snapshots (3.4.x): Nur erzeugt, wenn `convergence_probe` gesetzt, Indizes exakt wie angefordert.
- Excel Export (4.3.x): Datei generiert, fehlt `openpyxl` â†’ Warnung statt Crash.

### QualitÃ¤tssicherung vor Haken

Mindestens lokal prÃ¼fen:
- Keine neuen Tracebacks bei Standardlauf ohne Config (`python simulation_balise_error.py`)
- Lauf mit YAML + Seed liefert reproduzierbare ersten 5 Werte.
- JSON enthÃ¤lt `schema_version`, `model_version`, `config_hash`.

### Eskalation / Offene Punkte

Falls Blockade (z.B. fehlende Bibliothek), Task mit `[!]` markieren und im Ã„nderungslog vermerken.

